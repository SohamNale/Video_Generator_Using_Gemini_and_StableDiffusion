{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV5dRNQrnr3E"
      },
      "outputs": [],
      "source": [
        "!pip install pydub\n",
        "!pip install gtts\n",
        "!pip install diffusers --upgrade\n",
        "!pip install invisible_watermark transformers accelerate safetensors\n",
        "!pip install edge-tts\n",
        "!pip install mutagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oLRkFTenzq1"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip, concatenate_videoclips,AudioFileClip\n",
        "from gtts import gTTS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04mPHeuRn4R6"
      },
      "outputs": [],
      "source": [
        "genai.configure(api_key=\"Use your gemini api key here\")\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33lXs640n9Yb"
      },
      "outputs": [],
      "source": [
        "def chat(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5d_GoyDn9b6"
      },
      "outputs": [],
      "source": [
        "#chat(\"What is AI\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ANJDbkWn9kh"
      },
      "outputs": [],
      "source": [
        "# Step 3: Load pre-trained model\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
        "pipe = pipe.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRZ0pnmvn9nE"
      },
      "outputs": [],
      "source": [
        "start = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IH5n3HpFn9ps"
      },
      "outputs": [],
      "source": [
        "if start == 1:\n",
        "  # 1. Story telling\n",
        "  context=\"\"\"You are a professional story teller skilled in adventure, scifi, comedy, fiction, magic, romance, thriller and scary stories.\n",
        "You must tell the stories in less than 200 words and also stick to the theme of the story.\n",
        "Optionaly you can include anime/cartoon characters. The user will input [adventure, scifi, comedy, fiction, magic, romance, thriller, scary]\n",
        "any topic from these and you have to make a story around it and remember to make it in less than 200 words, also the user can input a combination of different topics like [fiction, scary, adventure] and you have to make a story considering all the topics.\n",
        "The following is the topic from the user: \"\"\"\n",
        "elif start == 2:\n",
        "  # 2. Productivity coach\n",
        "  context = \"\"\" You are a retired ceo of multinational tech company who gives advice/tips on any of the given topics ['financial independence', 'productivity', 'time management', 'self improvement', 'mental peace'].\n",
        "The user will input ['financial independence', 'productivity', 'time management', 'self improvement', 'mental peace'] any topic from these and you give a 200 words advice/tips on any one of the one above topic and stick to the same topic throughout the text.\n",
        "You can optionaly take inspiration from books or blogs of productivity and time management.\n",
        "The following is the topic from the user: \"\"\"\n",
        "elif start == 3:\n",
        "  # 3. Facts Teller\n",
        "  context = \"\"\" You are geek and nerd in knowing all the facts related to topics like ['tech fact', 'eductional fact', 'funny fact', 'historical fact', 'movie fact', 'scary fact'].\n",
        "The user will input ['financial independence', 'productivity', 'time management', 'self improvement', 'mental peace'] any topic from these and you give a 200 words fact related to any one of the one above topic and stick to the same topic throughout the text.\n",
        "You can take inspiration from internet and books to check if the correct or not. Only give correct facts.\n",
        "The following is the topic from the user: \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIeDWCGln9sB"
      },
      "outputs": [],
      "source": [
        "if start == 1:\n",
        "  # 1. Story telling\n",
        "  a=\"\"\"You are professional prompt engineer task with converting a text story into image generation prompts which can be used to generate images corresponding whats happening in the story.\n",
        "Put each prompt following the sequence of the story in a Python string format separated by ';' and don't use single or double quotes. Don't add 'python\\nprompts = ' or 'prompts = ' at the start and also dont give '\\n' in the prompts just give the prompts.\n",
        "Create exactly 20 prompts to generate 20 images for the story. Take the general idea of whats happening in the story and create elobrate prompts for the story.\n",
        "Make the prompts in meaningful sentences which stable diffusion model can understand and generate images.\n",
        "Following is the story: \"\"\"\n",
        "elif start == 2:\n",
        "  # 2. Productivity coach\n",
        "  a=\"\"\"You are professional prompt engineer task with converting a text productivity advice/tips into image generation prompts which can be used to generate images corresponding whats spoken in the text.\n",
        "Put each prompt following the sequence of the text in a Python string format separated by ';' and don't use single or double quotes. Don't add 'python\\nprompts = ' or 'prompts = ' at the start and also dont give '\\n' in the prompts just give the prompts.\n",
        "Create exactly 20 prompts to generate 20 images for the text. Take the general idea of whats happening in the productivity text and create elobrate prompts for the text.\n",
        "Make the prompts in meaningful sentences which stable diffusion model can understand and generate images.\n",
        "Following is the productivity advice/tip text: \"\"\"\n",
        "elif start == 3:\n",
        "  # 3. Facts Teller\n",
        "  a=\"\"\"You are professional prompt engineer task with converting a text related to facts into image generation prompts which can be used to generate images corresponding whats spoken in the text.\n",
        "Put each prompt following the sequence of the text in a Python string format separated by ';' and don't use single or double quotes. Don't add 'python\\nprompts = ' or 'prompts = ' at the start and also dont give '\\n' in the prompts just give the prompts.\n",
        "Create exactly 20 prompts to generate 20 images for the text. Take the general idea of whats happening in the text related to facts and create elobrate prompts for the text.\n",
        "Make the prompts in meaningful sentences which stable diffusion model can understand and generate images.\n",
        "Following is the fact related text: \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXQwMWgNn9vf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# Step 2: Parse text data\n",
        "def parse_text(text):\n",
        "    # Implement your text parsing logic here\n",
        "    # Extract relevant descriptions for each scene\n",
        "    x=chat(a+text)\n",
        "    txt= x.split(\";\")\n",
        "    while len(txt)>20:\n",
        "      txt.pop(random.randint(0, len(txt) - 1))\n",
        "    return(txt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NQ5fbhhotbT"
      },
      "outputs": [],
      "source": [
        "def generate_images(model, text_descriptions, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "    i=100\n",
        "    for description in text_descriptions:\n",
        "        # Preprocess the text if needed\n",
        "        # Feed the text description to the model to generate an image\n",
        "        generator = torch.Generator(\"cuda\").manual_seed(1024)\n",
        "        generated_image = model(description, generator=generator, height=1280, width=720).images[0]\n",
        "        i+=1\n",
        "        #generated_image = model.generate_image(description)\n",
        "        # Save the generated image\n",
        "        #save_image(generated_image, f\"{description[:20]}.png\")  # Saving with the first 20 characters of the description as filename\n",
        "        generated_image.save(os.path.join(output_folder, f\"{str(i)}.png\"))\n",
        "        #save_image(generated_image, os.path.join(output_folder, f\"{description[:20]}.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N02iVOxootec"
      },
      "outputs": [],
      "source": [
        "from moviepy.video.VideoClip import ImageClip\n",
        "\n",
        "# Function to create a video from images with each frame lasting 2 seconds\n",
        "def create_video(images_folder, output_video_path, duration_per_frame=30):\n",
        "    # Get list of image files in the folder\n",
        "    image_files = sorted([os.path.join(images_folder, f) for f in os.listdir(images_folder) if f.endswith('.png')])\n",
        "\n",
        "    # Create a list of ImageClips with each image lasting for the specified duration\n",
        "    clips = [ImageClip(img).set_duration(duration_per_frame) for img in image_files]\n",
        "\n",
        "    # Concatenate all the ImageClips\n",
        "    video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "    # Write the video file\n",
        "    video.write_videofile(output_video_path, codec='libx264', fps=30)  # FPS here is for smooth playback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiVLdrJTothA"
      },
      "outputs": [],
      "source": [
        "import edge_tts\n",
        "\n",
        "def text_to_audio(text, audio_path):\n",
        "    VOICE = \"en-GB-SoniaNeural\"\n",
        "    communicate = edge_tts.Communicate(text, VOICE)\n",
        "    communicate.save_sync(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78HwK_zqotjn"
      },
      "outputs": [],
      "source": [
        "# Function to merge audio with video\n",
        "def merge_audio_video(audio_path, video_path, output_path):\n",
        "      video = VideoFileClip(video_path)\n",
        "      audio = AudioFileClip(audio_path)\n",
        "      video = video.set_audio(audio)\n",
        "      video.write_videofile(output_path, codec='libx264')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPqUtmWVotmM"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def final_audio(initial_audio_path):\n",
        "  # Load the audio file\n",
        "  audio = AudioSegment.from_file(initial_audio_path)  # Replace with your file path\n",
        "\n",
        "  # Check the length of the audio\n",
        "  if len(audio) > 59000:  # 59 seconds in milliseconds\n",
        "      # Trim the audio to the first 59 seconds\n",
        "      audio = audio[:59000]\n",
        "\n",
        "  # Export the trimmed or padded audio\n",
        "  audio.export(\"output_audio.mp3\", format=\"mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvk_M6rcoto3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "if start == 1:\n",
        "  # 1. Story telling\n",
        "  topic=['adventure', 'scifi', 'comedy', 'fiction', 'magic', 'romance', 'thriller', 'scary']\n",
        "  random_topic = random.sample(topic, 1)\n",
        "elif start == 2:\n",
        "  # 2. Productivity coach\n",
        "  topic=['financial independence', 'productivity', 'time management', 'self improvement', 'mental peace']\n",
        "  random_topic = random.sample(topic, 1)\n",
        "elif start == 3:\n",
        "  # 3. Facts Teller\n",
        "  topic=['tech fact', 'eductional fact', 'funny fact', 'historical fact', 'movie fact', 'scary fact']\n",
        "  random_topic = random.sample(topic, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KftF-tXotsZ"
      },
      "outputs": [],
      "source": [
        "x=''\n",
        "for i in random_topic:\n",
        "    x=x+i+\" \"\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zu0Iz1to6lf"
      },
      "outputs": [],
      "source": [
        "text=chat(context+x)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMMFVS_yo6oJ"
      },
      "outputs": [],
      "source": [
        "def output(text):\n",
        "\n",
        "  text_descriptions = parse_text(text)\n",
        "  #print(text_descriptions)\n",
        "  # Step 2: Load pre-trained model\n",
        "  model = pipe\n",
        "  # Step 3 & 4: Generate images from text\n",
        "  #generate_images(model, text_descriptions, output_folder)\n",
        "  output_folder = \"output_images\"\n",
        "  generate_images(model, text_descriptions, output_folder)\n",
        "\n",
        "\n",
        "  # Example usage\n",
        "  images_folder = \"/content/output_images\"\n",
        "  output_video_path = \"output_video.mp4\"\n",
        "  create_video(images_folder, output_video_path, duration_per_frame=3)\n",
        "\n",
        "\n",
        "  initial_audio_path = \"initial_output_audio.mp3\"\n",
        "  video_path = \"/content/output_video.mp4\"\n",
        "  output_path = \"final_output.mp4\"\n",
        "  # Convert text to audio\n",
        "  #text_to_audio(text, audio_path)\n",
        "  text_to_audio(text, initial_audio_path)\n",
        "  final_audio(initial_audio_path)\n",
        "  audio_path = \"output_audio.mp3\"\n",
        "\n",
        "  # Merge audio with video\n",
        "  merge_audio_video(audio_path, video_path, output_path)\n",
        "  video_path = \"final_output.mp4\"\n",
        "  return video_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_qSGS3Uo6qp"
      },
      "outputs": [],
      "source": [
        "video_path = output(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asWw0ORCo6tB"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def play_video_in_colab(video_path):\n",
        "    # Encode video to base64\n",
        "    with open(video_path, \"rb\") as video_file:\n",
        "        video_data = video_file.read()\n",
        "        video_base64 = b64encode(video_data).decode()\n",
        "\n",
        "    # Create HTML for displaying video\n",
        "    video_html = f\"\"\"\n",
        "    <video width=\"640\" height=\"360\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{video_base64}\" type=\"video/mp4\">\n",
        "        Your browser does not support the video tag.\n",
        "    </video>\n",
        "    \"\"\"\n",
        "\n",
        "    # Display the video\n",
        "    return HTML(video_html)\n",
        "\n",
        "# Example usage\n",
        "video_path = \"final_output.mp4\" # Replace with the actual video path\n",
        "play_video_in_colab(video_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
